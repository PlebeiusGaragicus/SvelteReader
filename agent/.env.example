# LangGraph Agent Environment Variables
# Uses OpenAI-compatible endpoints - does NOT default to OpenAI

# Required: OpenAI-compatible API endpoint
# Examples:
#   Ollama:     http://localhost:11434/v1
#   vLLM:       http://localhost:8000/v1
#   LM Studio:  http://localhost:1234/v1
#   OpenRouter: https://openrouter.ai/api/v1
#   Together:   https://api.together.xyz/v1
LLM_BASE_URL=http://localhost:11434/v1

# Required: Model name to use
# Examples: llama3.2, mistral, codellama, etc.
LLM_MODEL=qwen3-coder-30b-a3b-instruct-mlx

# Optional: API key (some endpoints like Ollama don't require one)
# Use "ollama" for Ollama, "lm-studio" for LM Studio, or your actual key
LLM_API_KEY=ollama

# LangSmith tracing (optional)
LANGSMITH_API_KEY=lsv2_...
LANGCHAIN_PROJECT=PROJECTNAME...
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_TRACING_V2=true